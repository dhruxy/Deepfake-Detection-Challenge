{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a715887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2b974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.zeros([1660,256,256,3], dtype = np.float32)\n",
    "labels_train = np.zeros(1660)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a644827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path, max_frames=30, resize=(256, 256)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    i = 0\n",
    "    frames = np.zeros([256,256,3], dtype = np.float32)\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frame = frame/255\n",
    "            i += 1\n",
    "            if i == frame_1:\n",
    "                frames = frame\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "def cut_save(main_dir,mod):\n",
    "    i = 0\n",
    "    for x in os.listdir(main_dir):\n",
    "        print(x)\n",
    "        td = main_dir+x+'/'\n",
    "        for file in os.listdir(td):\n",
    "            fl = os.path.join(td, file)\n",
    "            print(fl)\n",
    "            videos = load_video(fl)\n",
    "            if mod == 'train':\n",
    "                train[i] = (videos)\n",
    "                \n",
    "                if x =='real':\n",
    "                    labels_train[i] = 1\n",
    "                elif x == 'fake':\n",
    "                    labels_train[i] = 0\n",
    "                i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1294a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../Focus/Data/'\n",
    "cut_save(DATA_DIR,\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf4f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_train[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78902cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(train,labels_train,test_size=0.02, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90a2ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len = y_test.shape\n",
    "print(test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d77adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[113])\n",
    "plt.show()\n",
    "print(y_train[112])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b6579a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Reshape, Concatenate, LeakyReLU\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fd05dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "layers = tf.keras.layers\n",
    "models = tf.keras.models\n",
    "losses = tf.keras.losses\n",
    "optimizers = tf.keras.optimizers \n",
    "metrics = tf.keras.metrics\n",
    "utils = tf.keras.utils\n",
    "callbacks = tf.keras.callbacks\n",
    "layers = tf.keras.layers\n",
    "models = tf.keras.models\n",
    "ImageDataGenerator = tf.keras.preprocessing.image.ImageDataGenerator\n",
    "losses = tf.keras.losses\n",
    "optimizers = tf.keras.optimizers \n",
    "metrics = tf.keras.metrics\n",
    "utils = tf.keras.utils\n",
    "callbacks = tf.keras.callbacks\n",
    "plot_model = tf.keras.utils.plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44d57b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__():\n",
    "        self.model = 0\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        return self.model.train_on_batch(x, y)\n",
    "    \n",
    "    def get_accuracy(self, x, y):\n",
    "        return self.model.test_on_batch(x, y)\n",
    "    \n",
    "    def load(self, path):\n",
    "        self.model.load_weights(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "673f4a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MesoNet class using the Classifier\n",
    "\n",
    "class Meso4(Classifier):\n",
    "    def __init__(self, learning_rate = 0.001):\n",
    "        self.model = self.init_model()\n",
    "        optimizer = Adam(learning_rate = learning_rate)\n",
    "        self.model.compile(optimizer = optimizer,\n",
    "                           loss = 'mae',\n",
    "                           metrics = ['accuracy'])\n",
    "    \n",
    "    def init_model(self): \n",
    "        x = Input(shape = (256,256,3))\n",
    "        \n",
    "        x1 = Conv2D(8, (3, 3), padding='same', activation = 'relu')(x)\n",
    "        x1 = BatchNormalization()(x1)\n",
    "        x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n",
    "        \n",
    "        x2 = Conv2D(8, (5, 5), padding='same', activation = 'relu')(x1)\n",
    "        x2 = BatchNormalization()(x2)\n",
    "        x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)\n",
    "        \n",
    "        x3 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x2)\n",
    "        x3 = BatchNormalization()(x3)\n",
    "        x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n",
    "        \n",
    "        x4 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x3)\n",
    "        x4 = BatchNormalization()(x4)\n",
    "        x4 = MaxPooling2D(pool_size=(4, 4), padding='same')(x4)\n",
    "        \n",
    "        y = Flatten()(x4)\n",
    "        y = Dropout(0.5)(y)\n",
    "        y = Dense(16)(y)\n",
    "        y = LeakyReLU(alpha=0.1)(y)\n",
    "        y = Dropout(0.5)(y)\n",
    "        y = Dense(1, activation = 'sigmoid')(y)\n",
    "\n",
    "        return Model(inputs = x, outputs = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3628cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccuracyHistory(callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "        self.loss = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        self.loss.append(logs.get('loss'))\n",
    "        self.val_loss.append(logs.get('val_loss'))\n",
    "\n",
    "history = AccuracyHistory()\n",
    "earlyStopping = callbacks.EarlyStopping(monitor='val_loss', patience=8,min_delta=1e-5, verbose=0, mode='min')\n",
    "mcp_save = callbacks.ModelCheckpoint('../Focus/weights/Video1.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = callbacks.ReduceLROnPlateau(monitor='val_loss',patience=1, verbose=2,factor=0.5,min_lr=0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26bc94c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_7 (TimeDist (None, 30, 1)             28073     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 30, 40)            6720      \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 30, 160)           6560      \n",
      "_________________________________________________________________\n",
      "globale (GlobalAveragePoolin (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "last (Dense)                 (None, 2)                 322       \n",
      "=================================================================\n",
      "Total params: 41,675\n",
      "Trainable params: 41,579\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "meso = Meso4()\n",
    "meso.load('../Focus/weights/Meso4_DF.h5')\n",
    "cnn = models.Sequential()\n",
    "cnn.add(meso.model)\n",
    "cnn.add(layers.Flatten())\n",
    "#cnn.add(layers.Dense(1024, activation='relu'))\n",
    "#cnn.add(layers.Dropout(0.3))\n",
    "#cnn.add(layers.Dense(512, activation='relu'))\n",
    "#cnn.add(layers.Dropout(0.3))\n",
    "#cnn.add(layers.LSTM(40))\n",
    "# define LSTM model\n",
    "model = models.Sequential()\n",
    "model.add(layers.TimeDistributed(cnn,  input_shape=(30, 256, 256, 3)))\n",
    "model.add(layers.LSTM(40 , return_sequences=True))\n",
    "#model.add(layers.Dense(num_classes, activation=\"sigmoid\"))\n",
    "#model.add(layers.Dropout(0.3))\n",
    "model.add(layers.TimeDistributed(layers.Dense(160, activation='relu')))\n",
    "model.add(layers.GlobalAveragePooling1D(name=\"globale\"))\n",
    "'''\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "'''\n",
    "model.add(layers.Dense(num_classes, activation=\"sigmoid\" , name=\"last\"))\n",
    "adam = optimizers.Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "# model.load_weights('Deepfake.hdf5')\n",
    "rms = optimizers.RMSprop()\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf61190",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# meso.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a40c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e8a58e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "meso.model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split = 0.1,\n",
    "          callbacks=[mcp_save,history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3057ea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_test\n",
    "y = y_test\n",
    "pred = meso.predict(X)\n",
    "count1 = 0\n",
    "for i in range(test_len[0]):\n",
    "    print(f\"\\nCorrect prediction: {round(pred[i][0])==y[i]}\")\n",
    "    if(round(pred[i][0])==y[i]):\n",
    "        count1 += 1;\n",
    "print(count1/test_len[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57215e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.zeros([518,256,256,3], dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4307bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Focus/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e700ba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a00fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_all_videos(df, root_dir, frame):\n",
    "    num_samples = len(df)\n",
    "    video_paths = df[\"id\"].values.tolist()\n",
    "    # For each video.\n",
    "    for idx, path in enumerate(video_paths):\n",
    "#         print(idx,path)\n",
    "        # Gather all its frames and add a batch dimension.\n",
    "        frames = load_video(os.path.join(root_dir, path),frame)\n",
    "        test[idx] = frames\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb2199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frm = 1\n",
    "num_f = 0 \n",
    "sum1 = np.zeros([518])\n",
    "label = np.zeros([518])\n",
    "while frm <= 25:\n",
    "    print(frm)\n",
    "    prepare_all_videos(df, \"../Focus/test_face/\" ,frm)\n",
    "    num_f += 1\n",
    "    frm += 5\n",
    "    \n",
    "    pred = meso.predict(test)\n",
    "    for i in range(518):\n",
    "        sum1[i] += pred[i][0]\n",
    "for i in range(518):\n",
    "    label[i] = sum1[i]/num_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdd58ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de97f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = meso.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfd2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pred.shape)\n",
    "# pred_class_1 = np.zeros([518])\n",
    "# for i in range(518):\n",
    "#     pred_class_1[i] = pred[i][0]\n",
    "# print(pred_class_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f43ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = pred_class_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf723b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(518):\n",
    "    label[i] = round(label[i])\n",
    "label = label.astype(int)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b94de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pred.shape)\n",
    "# pred_class = np.zeros([518])\n",
    "# for i in range(518):\n",
    "#     pred_class[i] = round(pred[i][0])\n",
    "# label = pred_class.astype(int)\n",
    "# print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de86bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df[\"id\"].values.tolist()\n",
    "list_of_tuples = list(zip(ids, label)) \n",
    "df2 = pd.DataFrame(list_of_tuples, columns = ['id', 'label']) \n",
    "df2.to_csv('../Focus/submission_13.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c5dcf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfod",
   "language": "python",
   "name": "tfod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
